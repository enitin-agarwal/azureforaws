{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# データを操作する\r\n",
        "\r\n",
        "データは、機械学習モデルが構築される基盤です。クラウドで一元的にデータを管理し、複数のワークステーションとコンピューティング ターゲットで実験を実行してモデルをトレーニングしているデータ サイエンティストのチームがアクセスできるようにすることは、プロフェッショナルなデータ サイエンス ソリューションでは重要です。\r\n",
        "\r\n",
        "このノートブックでは、データを操作するための 2 つの Azure Machine Learning オブジェクト、*データストア*と*データセット*について学びます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ワークスペースに接続する\r\n",
        "\r\n",
        "作業を開始するには、ワークスペースに接続します。\r\n",
        "\r\n",
        "> **注**: Azure サブスクリプションでまだ認証済みのセッションを確立していない場合は、リンクをクリックして認証コードを入力し、Azure にサインインして認証するよう指示されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# 保存された構成ファイルからワークスペースを読み込む\r\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## データストアを操作する\r\n",
        "\r\n",
        "Azure ML では、*データストア*は、Azure Storage Blob コンテナーのようなストレージ場所への参照です。あらゆるワークスペースには既定のデータストアがあります。通常は、ワークスペースで作成された Azure Storage Blob コンテナーです。異なる場所に格納されているデータを使用する必要がある場合は、ワークスペースにカスタム データストアを追加して、既定に設定することができます。\r\n",
        "\r\n",
        "### データストアを表示する\r\n",
        "\r\n",
        "次のコードを実行してワークスペースでデータストアを判定します:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 既定のデータストアを取得する\r\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "# すべてのデータストアを列挙し、どちらが既定かを示す\r\n",
        "for ds_name in ws.datastores:\n",
        "    print(ds_name, \"- Default =\", ds_name == default_ds.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "また、[Azure Machine Learning Studio](https://ml.azure.com) のワークスペースに関する「**データストア**」ページでワークスペースのデータストアを表示して管理することもできます。\r\n",
        "\r\n",
        "### データストアにデータをアップロードする\r\n",
        "\r\n",
        "利用可能なデータストアを特定したので、実際に実験スクリプトが実行されている場所に関係なく、ワークスペースで実行中の実験にアクセスできるように、ローカル ファイル システムからファイルをアップロードできます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'], # Upload the diabetes csv files in /data\n",
        "                       target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
        "                       overwrite=True, # Replace existing files of the same name\n",
        "                       show_progress=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## データセットを操作する\r\n",
        "\r\n",
        "Azure Machine Learning は*データセット*というかたちでデータの抽象化を提供します。データセットは、実験で使用したい特定のデータのセットへの参照で、バージョン管理されています。データセットは*表形式*または*ファイル*ベースのいずれかになります。\r\n",
        "\r\n",
        "### 表形式データセットを作成する\r\n",
        "\r\n",
        "データストアにアップロードした糖尿病データからデータセットを作成し、最初の 20 件のレコードを表示してみましょう。この場合、データは CSV ファイル内の構造化された形式なので、*表形式*のデータセットを使用します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "# 既定のデータストアを取得する\r\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "#データストア上のパスから表形式のデータセットを作成する (しばらく時間がかかる場合があります)\r\n",
        "tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
        "\n",
        "# 最初の 20 行を Pandas データフレームとして表示する\r\n",
        "tab_data_set.take(20).to_pandas_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "上のコードでわかるように、表形式のデータセットを Pandas データフレームに変換するのは簡単で、一般的な Python の手法を使用してデータを操作できます。\r\n",
        "\r\n",
        "### ファイル データセットを作成する\r\n",
        "\r\n",
        "作成したデータセットは、データセット定義に含まれる構造化ファイル内のすべてのデータを含むデータフレームとして読み取ることができる*表形式*のデータセットです。これは表形式のデータに適していますが、機械学習のシナリオによっては、非構造化データの操作が必要となる場合があります。または、単に自分のコード内のファイルからデータの読み取り処理を行うことが必要となる場合もあります。これを実現するには、*ファイル* データセットを使用して、ファイルのデータを読み取るために使用できる仮想マウント ポイント内のファイル パスのリストを作成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#データストア上のパスからファイル データセットを作成する (しばらく時間がかかる場合があります)\r\n",
        "file_data_set = Dataset.File.from_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
        "\n",
        "# データセット内のファイルを取得する\r\n",
        "for file_path in file_data_set.to_path():\n",
        "    print(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### データセットを登録する\r\n",
        "\r\n",
        "これで、糖尿病データを参照するデータセットを作成したので、それらを登録して、ワークスペースで実行されている実験に簡単にアクセスできるようにすることができます。\r\n",
        "\r\n",
        "表形式のデータセットを**糖尿病データセット**、ファイル データセットを**糖尿病ファイル**として登録します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 表形式のデータセットを登録する\r\n",
        "try:\n",
        "    tab_data_set = tab_data_set.register(workspace=ws, \n",
        "                                        name='diabetes dataset',\n",
        "                                        description='diabetes data',\n",
        "                                        tags = {'format':'CSV'},\n",
        "                                        create_new_version=True)\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "\n",
        "# ファイル データセットを登録する\r\n",
        "try:\n",
        "    file_data_set = file_data_set.register(workspace=ws,\n",
        "                                            name='diabetes file dataset',\n",
        "                                            description='diabetes files',\n",
        "                                            tags = {'format':'CSV'},\n",
        "                                            create_new_version=True)\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "\n",
        "print('Datasets registered')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[Azure Machine Learning Studio](https://ml.azure.com) のワークスペースに関する「**データセット**」ページでデータセットを表示して管理できます。ワークスペース オブジェクトからもデータセットのリストを取得できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Datasets:\")\n",
        "for dataset_name in list(ws.datasets.keys()):\n",
        "    dataset = Dataset.get_by_name(ws, dataset_name)\n",
        "    print(\"\\t\", dataset.name, 'version', dataset.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "データセットをバージョン管理できるため、以前の定義に依存する既存の実験やパイプラインを壊すことなくデータセットを再定義できます。既定では、名前付きデータセットの最新バージョンが返されますが、次のようにバージョン番号を指定することで、特定のバージョンのデータセットを取得できます。\r\n",
        "\r\n",
        "```python\r\n",
        "dataset_v1 = Dataset.get_by_name(ws, 'diabetes dataset', version = 1)\r\n",
        "```\r\n",
        "\r\n",
        "\r\n",
        "### 表形式データセットからモデルをトレーニングする\r\n",
        "\r\n",
        "データセットができたので、そこからモデルのトレーニングを開始する準備が整いました。データセットは、スクリプトの実行に使用される Estimator で、*入力*としてスクリプトに渡すことができます。\r\n",
        "\r\n",
        "次の 2 つのコード セルを実行して作成します。\r\n",
        "\r\n",
        "1.**diabetes_training_from_tab_dataset** という名前のフォルダー\r\n",
        "2.引数として渡される表形式のデータセットを使用して分類モデルをトレーニングするスクリプト。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# 実験ファイル用フォルダーを作成する\r\n",
        "experiment_folder = 'diabetes_training_from_tab_dataset'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "print(experiment_folder, 'folder created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $experiment_folder/diabetes_training.py\n",
        "# ライブラリをインポートする\r\n",
        "import os\n",
        "import argparse\n",
        "from azureml.core import Run, Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# スクリプト引数を取得する (正規化率とトレーニング データセット ID)\r\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
        "parser.add_argument(\"--input-data\", type=str, dest='training_dataset_id', help='training dataset')\n",
        "args = parser.parse_args()\n",
        "\n",
        "# 正規化ハイパーパラメーターを設定する (スクリプトに引数として渡される)\r\n",
        "reg = args.reg_rate\n",
        "\n",
        "# 実験実行コンテキストを取得する\r\n",
        "run = Run.get_context()\n",
        "\n",
        "# トレーニング データセットを取得する\r\n",
        "print(\"Loading Data...\")\n",
        "diabetes = run.input_datasets['training_data'].to_pandas_dataframe()\n",
        "\n",
        "# 特徴とラベルを分離する\r\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# データをトレーニング セットとテスト セットに分割する\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# ロジスティック回帰モデルをトレーニングする\r\n",
        "print('Training a logistic regression model with regularization rate of', reg)\n",
        "run.log('Regularization Rate',  np.float(reg))\n",
        "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "# 精度を計算する\r\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# AUC を計算する\r\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "# 出力フォルダーに保存されたファイルは、自動的に実験レコードにアップロードされます\r\n",
        "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
        "\n",
        "run.complete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **注**: スクリプトでは、データセットはパラメーター (または引数) として渡されます。表形式のデータセットの場合、この引数には登録済みのデータセットの ID が含まれます。このため、スクリプトにコードを書き込んで実験のワークスペースを実行コンテキストから取得した後、以下のような ID を利用してデータセットを取得できます。\r\n",
        ">\r\n",
        "> ```\r\n",
        "> run = Run.get_context()\r\n",
        "> ws = run.experiment.workspace\r\n",
        "> dataset = Dataset.get_by_id(ws, id=args.training_dataset_id)\r\n",
        "> diabetes = dataset.to_pandas_dataframe()\r\n",
        "> ```\r\n",
        ">\r\n",
        "> ただし、Azure Machine Learning 実行では、名前の付いたデータセットを参照して、これを実験の **input_datasets** コレクションに追加する引数が自動的に識別されます。このため、「フレンドリ名」を指定して、このコレクションからデータセットを取得することもできます (後述しますが、この名前は実験のスクリプト実行構成の引数定義で指定されます)。このアプローチは上記のスクリプトで使用されています。\r\n",
        "\r\n",
        "これでスクリプトを実験として実行し、スクリプトで読み取られるトレーニング データセットの引数を定義できます。\r\n",
        "\r\n",
        "> **注**: **Dataset** クラスは、**azureml-dataprep** パッケージの一部のコンポーネントに依存しているため、トレーニング実験の環境にこのパッケージを含める必要があります。**azureml-dataprep** パッケージは、**azure-defaults** パッケージに含まれています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "\n",
        "# 実験用の Python 環境を作成する（.yml ファイルから）\r\n",
        "env = Environment.from_conda_specification(\"experiment_env\", \"environment.yml\")\n",
        "\n",
        "# トレーニング データセットを取得する\r\n",
        "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
        "\n",
        "# スクリプト構成を作成する\r\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
        "                              script='diabetes_training.py',\n",
        "                              arguments = ['--regularization', 0.1, # Regularizaton rate parameter\n",
        "                                           '--input-data', diabetes_ds.as_named_input('training_data')], # Reference to dataset\n",
        "                              environment=env) \n",
        "\n",
        "# 実験を送信する\r\n",
        "experiment_name = 'mslearn-train-diabetes'\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "run = experiment.submit(config=script_config)\n",
        "RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **\"注:****--Input-data** 引数は*名前の付いた入力*としてデータセットを渡します。この中には、スクリプトが実験実行の **input_datasets** コレクションから読み取るために使用する、データセットの*フレンドリ名*が含まれます。**--Input-data** 引数の文字列値は実際には登録済みのデータセットの ID です。  代替アプローチとして、`diabetes_ds.id` を渡すこともできます。この場合、スクリプトはスクリプト引数からデータセット ID にアクセスし、これを使用してデータセットをワークスペースから取得できますが、**input_datasets** コレクションからは取得できません。\r\n",
        "\r\n",
        "初めて実験を実行すると、Python 環境のセットアップに時間がかかる場合があります。以降の実行はより高速になります。\r\n",
        "\r\n",
        "実験が完了したら、ウィジェットで、**azureml-logs/70_driver_log.txt** 出力ログと実行によって生成されたメトリックを表示します。\r\n",
        "\r\n",
        "### トレーニングされたモデルを登録する\r\n",
        "\r\n",
        "他のトレーニング実験と同様、Azure Machine Learning ワークスペースではトレーニングされたモデルを取得して登録することができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
        "                   tags={'Training context':'Tabular dataset'}, properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
        "\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ファイル データセットからモデルをトレーニングする\r\n",
        "\r\n",
        "*表形式*データセットでトレーニング データを使用してモデルをトレーニングする方法を見てきましたが、*ファイル* データセットについてはどうでしょうか。\r\n",
        "\r\n",
        "ファイル データセットを使用する場合、スクリプトに渡されるデータセット引数は、ファイル パスを含むマウント ポイントを表します。これらのファイルからデータを読み取る方法は、ファイル内のデータの種類と、そのデータを使用して何を行うかによって異なります。糖尿病 CSV ファイルの場合、Python **glob** モジュールを使用して、データセットによって定義された仮想マウント ポイント内のファイルのリストを作成し、それらをすべて単一のデータフレームに連結された Pandas データフレームに読み込むことができます。\r\n",
        "\r\n",
        "次の 2 つのコード セルを実行して作成します。\r\n",
        "\r\n",
        "1.**diabetes_training_from_file_dataset** という名前のフォルダー\r\n",
        "2.*入力*として渡されるファイル データセットを使用して分類モデルをトレーニングするスクリプト。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# 実験ファイル用フォルダーを作成する\r\n",
        "experiment_folder = 'diabetes_training_from_file_dataset'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "print(experiment_folder, 'folder created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $experiment_folder/diabetes_training.py\n",
        "# ライブラリをインポートする\r\n",
        "import os\n",
        "import argparse\n",
        "from azureml.core import Dataset, Run\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import glob\n",
        "\n",
        "# スクリプト引数を取得する (正規化率とファイル データセット マウント ポイント)\r\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
        "parser.add_argument('--input-data', type=str, dest='dataset_folder', help='data mount point')\n",
        "args = parser.parse_args()\n",
        "\n",
        "# 正規化ハイパーパラメーターを設定する (スクリプトに引数として渡される)\r\n",
        "reg = args.reg_rate\n",
        "\n",
        "# 実験実行コンテキストを取得する\r\n",
        "run = Run.get_context()\n",
        "\n",
        "# 糖尿病データセットを読み込む\r\n",
        "print(\"Loading Data...\")\n",
        "data_path = run.input_datasets['training_files'] # Get the training data path from the input\n",
        "# (ハードコードされた覚えやすい名前を利用したくない場合は、args.data_folder を使用することも可能)\r\n",
        "\n",
        "# ファイルを読み取る\r\n",
        "all_files = glob.glob(data_path + \"/*.csv\")\n",
        "diabetes = pd.concat((pd.read_csv(f) for f in all_files), sort=False)\n",
        "\n",
        "# 特徴とラベルを分離する\r\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# データをトレーニング セットとテスト セットに分割する\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# ロジスティック回帰モデルをトレーニングする\r\n",
        "print('Training a logistic regression model with regularization rate of', reg)\n",
        "run.log('Regularization Rate',  np.float(reg))\n",
        "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "# 精度を計算する\r\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# AUC を計算する\r\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "# 出力フォルダーに保存されたファイルは、自動的に実験レコードにアップロードされます\r\n",
        "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
        "\n",
        "run.complete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "表形式のデータセットと同様、ファイル データセットもフレンドリ名を使用して **input_datasets** コレクションから取得できます。また、スクリプト引数から取得することも可能です。この場合、ファイル データセットにはファイルへのマウント パスが含まれます (表形式のデータセットで渡されるデータセット ID とは異なります)。\r\n",
        "\r\n",
        "次に、データセットをスクリプトに渡す方法を変更する必要があります。スクリプトがファイルを読み取るパスを定義しなくてはなりません。これを行うには、**as_download** または **as_mount** メソッドのいずれかを使用できます。**as_download** を使用すると、ファイル データセットのファイルは、スクリプトを実行しているコンピューティングの一時的な場所にダウンロードされます。一方、**as_mount** は、ファイルを直接、データストアからストリームできるマウント ポイントを作成します。\r\n",
        "\r\n",
        "アクセス メソッドを **as_named_input** メソッドと組み合わせ、実験実行で **input_datasets** コレクションにデータセットを含めることができます (引数を `diabetes_ds.as_mount()` に設定するなどしてこれを省略すると、スクリプトはスクリプト引数からデータセット マウント ポイントにアクセスできますが、**input_datasets** コレクションからはアクセスできません)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "\n",
        "# トレーニング データセットを取得する\r\n",
        "diabetes_ds = ws.datasets.get(\"diabetes file dataset\")\n",
        "\n",
        "# スクリプト構成を作成する\r\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
        "                                script='diabetes_training.py',\n",
        "                                arguments = ['--regularization', 0.1, # Regularizaton rate parameter\n",
        "                                             '--input-data', diabetes_ds.as_named_input('training_files').as_download()], # Reference to dataset location\n",
        "                                environment=env) # Use the environment created previously\n",
        "\n",
        "# 実験を送信する\r\n",
        "experiment_name = 'mslearn-train-diabetes'\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "run = experiment.submit(config=script_config)\n",
        "RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "実験が完了したら、ウィジェットで **azureml-logs/70_driver_log.txt** 出力ログを表示し、ファイル データセットのファイルが一時的なフォルダーにダウンロードされており、スクリプトがファイルを読み取れることを確認します。\r\n",
        "\r\n",
        "### トレーニングされたモデルを登録する\r\n",
        "\r\n",
        "もう一度、実験によってトレーニングされたモデルを登録できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
        "                   tags={'Training context':'File dataset'}, properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
        "\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **詳細情報**: データセットを使用するトレーニングの詳細については、Azure ML ドキュメントの[データセットを使用するトレーニング](https://docs.microsoft.com/azure/machine-learning/how-to-train-with-datasets)を参照してください。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6 - AzureML",
      "language": "python",
      "name": "python3-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}